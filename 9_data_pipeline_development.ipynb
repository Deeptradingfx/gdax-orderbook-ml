{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of data pipelines from mongodb to ML model\n",
    "\n",
    "- Removal of matplotlib finanace module (deprecated)\n",
    "- Base package upgrades for core packages and utilities \n",
    "- Usage of raw_data_pipeline folder for development of data pipeline (Scikit-Learn & Tensorflow)\n",
    "- Usage of in-line markdown cells in-notebook for readability and consistency\n",
    "- Development groundwork for automation pipeline for automated hourly data scrape, cycling, and training for model through segregated instance or live online-based model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from json import loads\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Removal of matplotlib finance module imports (deprecated; implement modern replacement)\n",
    "import cbpro\n",
    "\n",
    "# Pymongo import (connection to local client DB)\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Preprocessing imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "# ML imports \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# Auto Support and Resistance/autoSR() import requirements\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "    # Import error for Pandas Datareader, cannot import name \"is_list_like\"\n",
    "    # https://github.com/pydata/pandas-datareader/issues/545\n",
    "    # Workaround for pandas 0.23: https://stackoverflow.com/a/50415484\n",
    "        # Before pandas_datareader import:\n",
    "        # pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from pandas_datareader import data, wb\n",
    "\n",
    "# Intermediate on-disk format for data pipeline from MongoDB/Pandas\n",
    "import feather\n",
    "    # Merged PR #43: \n",
    "    # https://github.com/timothyyu/gdax-orderbook-ml/pull/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# Import to check check for GPU availability for tensorflow backend\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Keras backend import to also check the above\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################################################    \n",
    "# Force/specify number of cores to use for Tensorflow with CPU backend\n",
    "    # Python GIL (https://wiki.python.org/moin/GlobalInterpreterLock) will force to single core \n",
    "    # Thus, explicitly define cores availble\n",
    "num_cores = 4\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "\n",
    "### Specify that both CPU and GPU devices are available (GPU assumed available):\n",
    "    # {'CPU' : 1, 'GPU' : 0}\n",
    "### Force Keras/TF to use CPU backend when GPU present by setting device_count (above) to:\n",
    "    # {'CPU' : 1, 'GPU' : 0}\n",
    "    \n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "Available devices (local):\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3780904617780733144\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9212319499\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7838043097504107627\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "==============================================\n",
      "Available GPUs:\n",
      "\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CPU/GPU availability for tensorflow backend\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(\"Available devices (local):\\n\")\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"==============================================\")\n",
    "print(\"Available GPUs:\\n\")\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Pandas Version\n",
    "    # 0.23.3 or above required\n",
    "pd.__version__\n",
    "    # Merged PR #43, pandas upgraded: \n",
    "        # https://github.com/timothyyu/gdax-orderbook-ml/pull/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook display variables\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# Boolean to drop existing mongo collection/scrape upon scrape() init\n",
    "    # Default = False\n",
    "dropFlag = False\n",
    "\n",
    "# Boolean to set size_delta to l2update values for first update to snapshot\n",
    "    # Inital value = False\n",
    "firstUpdate_both = False\n",
    "\n",
    "# Value to track if feature_creation_inital() was run\n",
    "    # Inital value = False\n",
    "inital_feature_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import 1 hour of raw data + L2 updates into localized mongodb instance for pipeline development\n",
    "\n",
    "1. Start new mongodb instance in new Terminal:\n",
    "`mongod`\n",
    "2. Copy mongo_raw from raw_data to raw_data_pipeline folder\n",
    "3. Navigate to raw_data_pipeline folder \n",
    "4. Import mongo_raw.json into localized mongo instance:\n",
    "`mongoimport --db btcusd_db --collection btcusd_collection --file mongo_raw.json`\n",
    "5. Verify db and collection presence with Terminal instance of mongod and/or MongoDB Compass\n",
    "    - After mongo_raw.json has been imported, only mongod instance needs to be started for mongoClient connection to be established\n",
    "    - Only necessary when using functions that require mongoDB connectivity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection establishment (MongoDB)\n",
    "    # Requires db and collection 'btcusd_db' and 'btcusd_collection' to be present on instance\n",
    "\n",
    "# Establish connection to GDAX public endpoint\n",
    "public_client = cbpro.PublicClient()\n",
    "\n",
    "# Mongo database and collection specification:\n",
    "mongo_client = MongoClient('mongodb://localhost:27017/')\n",
    "db = mongo_client.btcusd_db\n",
    "btcusd_collection = db.btcusd_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def scrape_start():\n",
    "    # Needs rewrite - see pull request #44:\n",
    "        # https://github.com/timothyyu/gdax-orderbook-ml/issues/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and parse data from Mongo into dataframes\n",
    "def load_parse_feather():\n",
    "    \n",
    "    # Collection specification (in database)\n",
    "    input_data = db.btcusd_collection \n",
    "    \n",
    "    # Create individual dataframes for main response types: snapshot, l2update\n",
    "    snapshot = pd.DataFrame(list(input_data.find({'type':'snapshot'})))\n",
    "    l2update = pd.DataFrame(list(input_data.find({'type':'l2update'})))\n",
    "    \n",
    "    ### snapshot/orderbook state response load and parse ###\n",
    "    \n",
    "    # Extract asks/bid individual column of array of arrays into lists\n",
    "    snapshot_asks = snapshot[['asks'][0]][0]\n",
    "    snapshot_bids = snapshot[['bids'][0]][0]\n",
    "    \n",
    "    # Convert list (of array of arrays) into dataframe\n",
    "    snapshot_asks_df =pd.DataFrame(snapshot_asks)\n",
    "    snapshot_bids_df =pd.DataFrame(snapshot_bids)\n",
    "    \n",
    "    # Rename columns to snapshot array format:\n",
    "        # snapshot array format: [price, size]\n",
    "            # [side, price, size] format \n",
    "        # Ask = sell price, bid = buy price\n",
    "    snapshot_asks_df.rename(columns ={0:'price',1:'size'}, inplace =True)\n",
    "    snapshot_bids_df.rename(columns ={0:'price',1:'size'}, inplace =True)\n",
    "    snapshot_asks_df['side'] = \"sell\"\n",
    "    snapshot_bids_df['side'] = \"buy\"\n",
    "    cols =['side','price','size']\n",
    "    snapshot_asks_df = snapshot_asks_df[cols]\n",
    "    snapshot_bids_df = snapshot_bids_df[cols]\n",
    "    \n",
    "    ### L2 update response load and parse ###\n",
    "    \n",
    "    # Restucture l2update to have [side,price,size] from 'changes' column\n",
    "    l2update_clean = l2update[['changes','time']]\n",
    "          \n",
    "    # Convert changes list of lists -> into array \n",
    "    l2_array = np.ravel(l2update_clean['changes']) \n",
    "    # Flatten the list and remove outer bracket using a list comprehension:\n",
    "    flattened = [val for sublist in l2_array for val in sublist]\n",
    "        # Reference: https://stackoverflow.com/questions/11264684/flatten-list-of-lists?\n",
    "    # Convert back to dataframe and combine with timestamps from l2update:\n",
    "    changes_df = pd.DataFrame.from_records(flattened)\n",
    "    # Add time column back to L2 update dataframe\n",
    "    l2update_formatted = pd.concat([changes_df,l2update_clean['time']],1)\n",
    "    # Rename columns for [side, price, size]:\n",
    "    l2update_formatted.rename({0:\"side\",1:\"price\",2:\"size\"}, axis ='columns',inplace=True)\n",
    "    \n",
    "    # Save parsed data to feather format\n",
    "        # API -> Mongo -> Dataframe -> .feather format\n",
    "    l2update_formatted.to_feather(\"raw_data_pipeline/l2update.feather\")\n",
    "    snapshot_asks_df.to_feather(\"raw_data_pipeline/snapshot_asks.feather\")\n",
    "    snapshot_bids_df.to_feather(\"raw_data_pipeline/snapshot_bids.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_load_feather():\n",
    "    global request_log_df\n",
    "    global snapshot_asks_df\n",
    "    global snapshot_bids_df\n",
    "    global l2update_df\n",
    "    \n",
    "    global l2update_15min_1\n",
    "    global l2update_15min_2\n",
    "    global l2update_15min_3\n",
    "    global l2update_15min_4\n",
    "  \n",
    "    # pandas.read_feather(path, nthreads=1)\n",
    "        # Parameter to specify number of threads when reading to dataframes is available\n",
    "        # Change nthreads parameter to 2 for laptop,2-4 for remote instance, and 4-6 on development machine (recommended)\n",
    "            # Thread parameter recommended for l2update_df due to I/O overhead\n",
    "    snapshot_asks_df = pd.read_feather(\"raw_data_pipeline/snapshot_asks.feather\")\n",
    "    snapshot_bids_df = pd.read_feather(\"raw_data_pipeline/snapshot_bids.feather\")\n",
    "    l2update_df = pd.read_feather(\"raw_data_pipeline/l2update.feather\",4)\n",
    "    request_log_df= pd.read_csv(\"raw_data_pipeline/request_log.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of mongoDB must be running/available to client machine for load_parse_feather():\n",
    "\n",
    "# Load and parse data from MongoDB into dataframes:\n",
    "load_parse_feather()\n",
    "\n",
    "# If Axis error on rename error, Pandas upgrade required:\n",
    "    # https://stackoverflow.com/questions/47800034/pandas-dataframe-rename-unexpected-keyword-argument-axis-when-using-mapper/47800303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from .feather data format into inital dataframes\n",
    "    # Data from raw_data_pipeline folder\n",
    "raw_data_load_feather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chart_15m_request(request_log_df):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iso</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request end</td>\n",
       "      <td>2018-04-24T04:52:17.094Z</td>\n",
       "      <td>1.524546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request start</td>\n",
       "      <td>2018-04-24T03:52:17.030Z</td>\n",
       "      <td>1.524542e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       iso         epoch\n",
       "0    request end  2018-04-24T04:52:17.094Z  1.524546e+09\n",
       "1  request start  2018-04-24T03:52:17.030Z  1.524542e+09"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sell</td>\n",
       "      <td>9693</td>\n",
       "      <td>0.16111052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sell</td>\n",
       "      <td>9693.85</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sell</td>\n",
       "      <td>9696.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sell</td>\n",
       "      <td>9699.24</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sell</td>\n",
       "      <td>9699.25</td>\n",
       "      <td>1.02998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   side    price        size\n",
       "0  sell     9693  0.16111052\n",
       "1  sell  9693.85        0.05\n",
       "2  sell   9696.6         0.1\n",
       "3  sell  9699.24       0.125\n",
       "4  sell  9699.25     1.02998"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_asks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buy</td>\n",
       "      <td>9692.99</td>\n",
       "      <td>9.79874518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy</td>\n",
       "      <td>9692.98</td>\n",
       "      <td>0.00254526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buy</td>\n",
       "      <td>9692.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy</td>\n",
       "      <td>9692.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buy</td>\n",
       "      <td>9692.69</td>\n",
       "      <td>9.64811343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  side    price        size\n",
       "0  buy  9692.99  9.79874518\n",
       "1  buy  9692.98  0.00254526\n",
       "2  buy  9692.95        0.05\n",
       "3  buy  9692.78        0.01\n",
       "4  buy  9692.69  9.64811343"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot_bids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function stack needs rewrite \n",
    "    # Removal of matplotlib finance (deprecated)\n",
    "    # Removal of invalid pandas functions\n",
    "    \n",
    "#def chart_15m_request(request_log_df):\n",
    "#def autoSR(dataframe):\n",
    "    # Save generated s/r to dataframe + text file/csv, pull request #33\n",
    "    # https://github.com/timothyyu/gdax-orderbook-ml/issues/33\n",
    "#def generate_chart(dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_15m_request(request_log_df):\n",
    "    \n",
    "    global chart_15m_df\n",
    "    request_start = request_log_df['iso'][1]\n",
    "    request_end = request_log_df['iso'][0]\n",
    "\n",
    "    # Request 15 minutes of candlestick (open high low close) data from API\n",
    "        # start time must be in ISO 8601 format for get_product_historic_rates()\n",
    "    chart_15m = public_client.get_product_historic_rates('BTC-USD', start = request_start,end = request_end, granularity=60)\n",
    "\n",
    "    # Convert chart data response into dataframes\n",
    "    chart_15m_df =pd.DataFrame.from_records(chart_15m,columns=[\"time\",\"low\", \"high\",\"open\" ,\"close\", \"volume\"])\n",
    "\n",
    "    # Reorder columns according to label order required by matplotlib finance package\n",
    "    chart_15m_df = chart_15m_df[[\"time\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "    # Reverse/sort timestamp order (without reversal chart labels/axis will be out of order)\n",
    "    chart_15m_df.sort_values(by='time',axis=0, inplace =True)\n",
    "\n",
    "    #Convert/sort time to datetime object (for matplotlib chart format requirement)\n",
    "    chart_15m_df['time'] =pd.to_datetime(chart_15m_df['time'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto support/resistance adapted into function \n",
    "    # Using estimate_bandwidth and meanshift() from sklearn.cluster library\n",
    "    # Source: Adapted from https://github.com/nakulnayyar/SupResGenerator\n",
    "    # Takes dataframe object with open/high/low/close values \n",
    "        # Returns list of auto-generated support and resistance levels for price action\n",
    "            # Can return as nearest int or actual precise levels if non-int\n",
    "        \n",
    "def autoSR(dataframe):\n",
    "    \n",
    "    global ml_results_modified\n",
    "    \n",
    "    #data = chart_15m_df.as_matrix(columns=['close'])\n",
    "        # .as_matrix future deprecation warning; use .values instead\n",
    "    data= dataframe['close'].values\n",
    "    # Reshape array into 2D array \n",
    "        # .values does not preserve 2D array; .as_matrix does, but is future deprecated\n",
    "    data = np.reshape(data, (-1, 2))\n",
    "    data2 = data\n",
    "    \n",
    "    bandwidth = estimate_bandwidth(data2, quantile=0.1, n_samples=100)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data2)\n",
    "    ml_results = []\n",
    "    for k in range(len(np.unique(ms.labels_))):\n",
    "            my_members = ms.labels_ == k\n",
    "            values = data[my_members, 0]    \n",
    "            ml_results.append(min(values))\n",
    "            ml_results.append(max(values))\n",
    "            # Remove duplicate S/R level values using sets\n",
    "            ml_set =set(ml_results)\n",
    "            ml_results = list(ml_set)\n",
    "            # Sort values before return output \n",
    "            ml_results.sort()\n",
    "            \n",
    "    # Convert to int and remove duplicates (including duplicates from truncation):    \n",
    "    # Convert ml_results into sorted int array\n",
    "    ml_results_modified = np.asarray(ml_results)\n",
    "    #ml_results_modified = np.trunc(ml_results_modified).astype(int)\n",
    "    #ml_results_modified = np.sort(ml_results_modified,kind = 'quicksort') \n",
    "    # Remove duplicates from int conversion\n",
    "    #ml_results_modified_set=set(ml_results_modified)\n",
    "    #ml_results_modified = list(ml_results_modified)\n",
    "    #ml_results_modified = np.sort(ml_results_modified,kind = 'quicksort')\n",
    "    #ml_results_modified\n",
    "            \n",
    "    return ml_results_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function must be updated to use python 3\n",
    "def autoSR_alt(dataframe, n):\n",
    "    \"\"\"\n",
    "    This function takes a numpy array of last traded price\n",
    "    and returns a list of support and resistance levels \n",
    "    respectively. n is the number of entries to be scanned.\n",
    "    \n",
    "    Source: https://kite.trade/forum/discussion/1047/a-simple-python-function-to-detect-support-resistance-levels\n",
    "    \"\"\"\n",
    "    from scipy.signal import savgol_filter as smooth\n",
    "    \n",
    "    # .as_matrix future deprecation warning; use .values instead\n",
    "    # ltp = dataframe.as_matrix(columns=['close'])\n",
    "    ltp = dataframe['close'].values\n",
    "   \n",
    "    #Required for x/y array length fix\n",
    "    ltp = np.ravel(ltp)\n",
    "    \n",
    "    #converting n to a nearest even number\n",
    "    if n%2 != 0:\n",
    "        n += 1\n",
    "    \n",
    "    n_ltp = ltp.shape[0]\n",
    "    print(\"Shaped coficient array:\",n_ltp)\n",
    "    print(\"Cofficients:\",len(ltp))\n",
    "    \n",
    "    # Smoothing the output curve\n",
    "    # Ref: \n",
    "        # https://github.com/scipy/scipy/blob/master/scipy/signal/_savitzky_golay.py\n",
    "    ltp_s = smooth(ltp, (n-1), 3) \n",
    "    print(\"Smoothed ltp_s:\",ltp_s)\n",
    "    \n",
    "    #taking a simple derivative\n",
    "    ltp_d = np.zeros(n_ltp)\n",
    "    ltp_d[1:] = np.subtract(ltp_s[1:], ltp_s[:-1])\n",
    "    print(\"ltp_s derivative:\",ltp_d)\n",
    " \n",
    "    resistance = []\n",
    "    support = []\n",
    "    \n",
    "    print(n_ltp)\n",
    "    print(n)\n",
    "    # Use range instead of xrange; xrange is python 2\n",
    "    \n",
    "    for item in ltp_d:\n",
    "        #print(item)\n",
    "        first = ltp_d[:(n//2)] #first half\n",
    "        last = ltp_d[(n//2):] #second half\n",
    "        r_1 = np.sum(first > 0)\n",
    "        r_2 = np.sum(last < 0)\n",
    "        #local maxima detection\n",
    "        if (r_1 == (n/2)) and (r_2 == (n/2)): \n",
    "            print(item)\n",
    "        \n",
    "    for i in range(n_ltp - n):\n",
    "        \n",
    "        #arr_sl = ltp_d.reshape((1, -1))\n",
    "        arr_sl = ltp_d[i:(i+n)]\n",
    "        \n",
    "        \n",
    "        first = arr_sl[:(n//2)] #first half\n",
    "        last = arr_sl[(n//2):] #second half\n",
    "        \n",
    "        r_1 = np.sum(first > 0)\n",
    "        r_2 = np.sum(last < 0)\n",
    "\n",
    "        s_1 = np.sum(first < 0)\n",
    "        s_2 = np.sum(last > 0)\n",
    "\n",
    "        #local maxima detection\n",
    "        if (r_1 == (n/2)) and (r_2 == (n/2)): \n",
    "            resistance.append(ltp[i+((n/2)-1)])\n",
    "\n",
    "        #local minima detection\n",
    "        if (s_1 == (n/2)) and (s_2 == (n/2)): \n",
    "            support.append(ltp[i+((n/2)-1)])\n",
    "    return support, resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function must be updated to use python 3\n",
    "def autoSR_alt(dataframe, n):\n",
    "    \"\"\"\n",
    "    This function takes a numpy array of last traded price\n",
    "    and returns a list of support and resistance levels \n",
    "    respectively. n is the number of entries to be scanned.\n",
    "    \n",
    "    Source: https://kite.trade/forum/discussion/1047/a-simple-python-function-to-detect-support-resistance-levels\n",
    "    \"\"\"\n",
    "    from scipy.signal import savgol_filter as smooth\n",
    "    \n",
    "    # .as_matrix future deprecation warning; use .values instead\n",
    "    # ltp = dataframe.as_matrix(columns=['close'])\n",
    "    ltp = dataframe['close'].values\n",
    "   \n",
    "    #Required for x/y array length fix\n",
    "    ltp = np.ravel(ltp)\n",
    "    \n",
    "    #converting n to a nearest even number\n",
    "    if n%2 != 0:\n",
    "        n += 1\n",
    "    \n",
    "    n_ltp = ltp.shape[0]\n",
    "    print(\"Shaped coficient array:\",n_ltp)\n",
    "    print(\"Cofficients:\",len(ltp))\n",
    "    \n",
    "    # Smoothing the output curve\n",
    "    # Ref: \n",
    "        # https://github.com/scipy/scipy/blob/master/scipy/signal/_savitzky_golay.py\n",
    "    ltp_s = smooth(ltp, (n-1), 4) \n",
    "    print(\"Smoothed ltp_s:\",ltp_s)\n",
    "    \n",
    "    #taking a simple derivative\n",
    "    ltp_d = np.zeros(n_ltp)\n",
    "    ltp_d[1:] = np.subtract(ltp_s[1:], ltp_s[:-1])\n",
    "    print(\"ltp_s derivative:\",ltp_d)\n",
    " \n",
    "    resistance = []\n",
    "    support = []\n",
    "    \n",
    "    #print(n_ltp)\n",
    "    #print(n)\n",
    "    \n",
    "    # Use range instead of xrange; xrange is python 2\n",
    "    first = ltp_d[:(n//2)] #first half\n",
    "    last = ltp_d[(n//2):] #second half\n",
    "    print(\"=====================================\")\n",
    "    print(\"first half: \\n\",first)\n",
    "    print(\"last half: \\n\",last)\n",
    "    r_1 = np.sum(first > 0)\n",
    "    r_2 = np.sum(last < 0)\n",
    "    s_1 = np.sum(first < 0)\n",
    "    s_2 = np.sum(last > 0)\n",
    "    print(r_1,r_2,s_1,s_2)\n",
    "    \n",
    "    for item in ltp_d:\n",
    "        #print(item)\n",
    "       \n",
    "       \n",
    "        #local maxima detection\n",
    "        if (r_1 == (n/2)) and (r_2 == (n/2)): \n",
    "            resistance.append(ltp[i+((n//2)-1)])\n",
    "        #local minima detection\n",
    "        if (s_1 == (n/2)) and (s_2 == (n/2)): \n",
    "            support.append(ltp[i+((n//2)-1)])\n",
    "\n",
    "    return support, resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart_15m_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaped coficient array: 60\n",
      "Cofficients: 60\n",
      "Smoothed ltp_s: [9179.8766324  9184.79104542 9189.14937195 9192.99037388 9196.35160951\n",
      " 9199.26943355 9201.77899713 9203.91424779 9205.70792949 9207.19158259\n",
      " 9208.39554387 9209.34894653 9210.07972018 9210.61459084 9210.97908094\n",
      " 9211.19750934 9211.29299128 9211.28743846 9211.20155895 9211.05485726\n",
      " 9210.86563431 9210.65098742 9210.42681034 9210.20779321 9210.00742262\n",
      " 9209.83798154 9209.71054937 9209.63500192 9209.62001141 9209.67304698\n",
      " 9209.23596152 9209.40335894 9209.6722734  9210.04555816 9210.52450328\n",
      " 9211.10883508 9211.79671614 9212.58474532 9213.46795772 9214.43982475\n",
      " 9215.49225404 9216.61558953 9217.7986114  9219.0285361  9220.29101635\n",
      " 9221.57014115 9222.84843575 9224.10686167 9225.3248167  9226.4801349\n",
      " 9227.54908659 9228.50637836 9229.32515308 9229.97698986 9230.43190409\n",
      " 9230.65834745 9230.62320785 9230.29180948 9229.62791281 9228.59371456]\n",
      "ltp_s derivative: [ 0.          4.91441302  4.35832653  3.84100193  3.36123563  2.91782404\n",
      "  2.50956358  2.13525066  1.7936817   1.4836531   1.20396128  0.95340266\n",
      "  0.73077365  0.53487066  0.3644901   0.21842839  0.09548195 -0.00555282\n",
      " -0.08587951 -0.14670169 -0.18922295 -0.21464689 -0.22417708 -0.21901712\n",
      " -0.20037059 -0.16944108 -0.12743217 -0.07554745 -0.01499051  0.05303557\n",
      " -0.43708546  0.16739743  0.26891446  0.37328476  0.47894512  0.5843318\n",
      "  0.68788106  0.78802917  0.88321241  0.97186702  1.0524293   1.12333549\n",
      "  1.18302187  1.2299247   1.26248026  1.2791248   1.2782946   1.25842592\n",
      "  1.21795503  1.1553182   1.06895169  0.95729177  0.81877471  0.65183678\n",
      "  0.45491424  0.22644335 -0.0351396  -0.33139837 -0.66389667 -1.03419825]\n",
      "=====================================\n",
      "first half: \n",
      " [ 0.          4.91441302  4.35832653  3.84100193  3.36123563  2.91782404\n",
      "  2.50956358  2.13525066  1.7936817   1.4836531   1.20396128  0.95340266\n",
      "  0.73077365  0.53487066  0.3644901   0.21842839  0.09548195 -0.00555282\n",
      " -0.08587951 -0.14670169 -0.18922295 -0.21464689 -0.22417708 -0.21901712\n",
      " -0.20037059 -0.16944108 -0.12743217 -0.07554745 -0.01499051  0.05303557]\n",
      "last half: \n",
      " [-0.43708546  0.16739743  0.26891446  0.37328476  0.47894512  0.5843318\n",
      "  0.68788106  0.78802917  0.88321241  0.97186702  1.0524293   1.12333549\n",
      "  1.18302187  1.2299247   1.26248026  1.2791248   1.2782946   1.25842592\n",
      "  1.21795503  1.1553182   1.06895169  0.95729177  0.81877471  0.65183678\n",
      "  0.45491424  0.22644335 -0.0351396  -0.33139837 -0.66389667 -1.03419825]\n",
      "17 5 12 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoSR_alt(chart_15m_df,len(chart_15m_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9192.  , 9192.01, 9196.99, 9200.01, 9202.2 , 9208.65, 9209.99,\n",
       "       9210.  , 9210.01, 9214.98, 9214.99, 9219.29, 9219.99, 9220.96,\n",
       "       9224.96, 9225.  , 9226.3 , 9232.02, 9235.  , 9237.  ])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoSR(chart_15m_df)\n",
    "ml_results_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPL finance calls --> replace with stock MPL or use different visualization library\n",
    "\n",
    "# Function to generate candlestick chart from candlestick data (API request)\n",
    "    # Calls autoSR() inside function to also plot support/resistance lines\n",
    "    \n",
    "def generate_chart(dataframe):\n",
    "\n",
    "    dataframe = chart_15m_df \n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, ax = plt.subplots(figsize=(20, 14))\n",
    "    \n",
    "    # Generate chart of past 15 minutes with autogenerated support and resistance levels:\n",
    "    candlestick2_ohlc(ax,chart_15m_df['open'],chart_15m_df['high'],\\\n",
    "                      chart_15m_df['low'],chart_15m_df['close'],width=2,\\\n",
    "                      colorup='k',colordown='r',alpha=.5)\n",
    "    \n",
    "    ax.set_xticklabels(chart_15m_df['time'] ,rotation=30,ha=\"right\")\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(17))\n",
    "        # n + 2 for proper label set at 20,18/20,14 chart size\n",
    "    plt.yticks(np.arange(int(min(chart_15m_df['low'])-10), max(chart_15m_df['high'])+10, 10))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USD)')\n",
    "    #ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    #fig.set_zorder(0)\n",
    "    #ax.set_zorder(1)\n",
    "    ax.tick_params(axis='y', pad=10)\n",
    "    ax.grid(which='major', linestyle='--', linewidth='0.2', color='b')\n",
    "    matplotlib.pyplot.title(\"15 Min BTC/USD with Support/Resistance Levels\")\n",
    "    \n",
    "    # call autoSR() to autogenerate support and resistance levels from chart data\n",
    "    ml_results_modified = autoSR(chart_15m_df)\n",
    "    \n",
    "    # Add S/R labels to chart\n",
    "        # count increment is used for staggering of labels in conjunction with modulus   \n",
    "    count = 1\n",
    "    for k in ml_results_modified:\n",
    "        # Plot each S/R level as horizontal line on chart\n",
    "        ax.axhline(y=k)\n",
    "        if count%3 == 0:\n",
    "            plt.text(y=k,s=k,x=count-5,color='blue',rotation=45,size ='large')\\\n",
    "            .set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "        if count%3 == 1:\n",
    "            plt.text(y=k,s=k,x=count+5,color='blue',rotation=45,size ='large')\\\n",
    "            .set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "        if count%3 == 2:\n",
    "            plt.text(y=k,s=k,x=count+16,color='blue',rotation=45, size ='large')\\\n",
    "            .set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "        count = count +1 \n",
    "    plt.savefig('saved_charts/chart_15m_generated.png')    \n",
    "    #plt.tight_layout()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_15m_request(request_log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iso</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request end</td>\n",
       "      <td>2018-04-24T04:52:17.094Z</td>\n",
       "      <td>1.524546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request start</td>\n",
       "      <td>2018-04-24T03:52:17.030Z</td>\n",
       "      <td>1.524542e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       iso         epoch\n",
       "0    request end  2018-04-24T04:52:17.094Z  1.524546e+09\n",
       "1  request start  2018-04-24T03:52:17.030Z  1.524542e+09"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2018-04-24 03:53:00</td>\n",
       "      <td>9192.00</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>9192.00</td>\n",
       "      <td>4.714037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2018-04-24 03:54:00</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>9192.00</td>\n",
       "      <td>7.134894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2018-04-24 03:55:00</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>9192.00</td>\n",
       "      <td>13.375614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2018-04-24 03:56:00</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>2.476776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2018-04-24 03:57:00</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>9192.0</td>\n",
       "      <td>9192.01</td>\n",
       "      <td>1.367583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time     open     high     low    close     volume\n",
       "59 2018-04-24 03:53:00  9192.00  9192.01  9192.0  9192.00   4.714037\n",
       "58 2018-04-24 03:54:00  9192.01  9192.01  9192.0  9192.00   7.134894\n",
       "57 2018-04-24 03:55:00  9192.01  9192.01  9192.0  9192.00  13.375614\n",
       "56 2018-04-24 03:56:00  9192.01  9192.01  9192.0  9192.01   2.476776\n",
       "55 2018-04-24 03:57:00  9192.01  9192.01  9192.0  9192.01   1.367583"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_15m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-24 04:48:00</td>\n",
       "      <td>9220.74</td>\n",
       "      <td>9227.65</td>\n",
       "      <td>9220.73</td>\n",
       "      <td>9220.74</td>\n",
       "      <td>10.831441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-24 04:49:00</td>\n",
       "      <td>9220.74</td>\n",
       "      <td>9234.24</td>\n",
       "      <td>9220.74</td>\n",
       "      <td>9232.02</td>\n",
       "      <td>16.893378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-24 04:50:00</td>\n",
       "      <td>9232.02</td>\n",
       "      <td>9232.50</td>\n",
       "      <td>9232.01</td>\n",
       "      <td>9232.50</td>\n",
       "      <td>3.705115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-24 04:51:00</td>\n",
       "      <td>9232.50</td>\n",
       "      <td>9236.40</td>\n",
       "      <td>9225.75</td>\n",
       "      <td>9226.30</td>\n",
       "      <td>24.274001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-24 04:52:00</td>\n",
       "      <td>9227.62</td>\n",
       "      <td>9227.62</td>\n",
       "      <td>9227.61</td>\n",
       "      <td>9227.62</td>\n",
       "      <td>13.208367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     open     high      low    close     volume\n",
       "4 2018-04-24 04:48:00  9220.74  9227.65  9220.73  9220.74  10.831441\n",
       "3 2018-04-24 04:49:00  9220.74  9234.24  9220.74  9232.02  16.893378\n",
       "2 2018-04-24 04:50:00  9232.02  9232.50  9232.01  9232.50   3.705115\n",
       "1 2018-04-24 04:51:00  9232.50  9236.40  9225.75  9226.30  24.274001\n",
       "0 2018-04-24 04:52:00  9227.62  9227.62  9227.61  9227.62  13.208367"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_15m_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the above data with autogenerated support and resistance levels for price \n",
    "    # Pass dataframe to autoSR() --> create chart + generate and plot auto S/R levels\n",
    "    # Pass dataframe to autoSR() --> just generate S/R levels and return as array\n",
    "\n",
    "#autoSR(chart_15m_df), generate_chart(chart_15m_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def feature_creation_inital():\n",
    "#def l2update_1hr_split(l2update_df):\n",
    "#def snapshot_join(snapshot_asks_df,snapshot_bids_df):\n",
    "#def apply_l2_update(snapshot_both_df,l2update_15min):\n",
    "\n",
    "#def chart_15m_request(request_log_df):\n",
    "    # Not respecting time format - pull req #9\n",
    "        #https://github.com/timothyyu/gdax-orderbook-ml/issues/9\n",
    "    # Requires rewrite - strip MPL dependecies\n",
    "    # Replace with plotly, pure matplotlib, or modern alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML-specific PR: ##\n",
    "    \n",
    "# train_test_split() does not work with shaped data (x features/y target)\n",
    "    #https://github.com/timothyyu/gdax-orderbook-ml/issues/22\n",
    "\n",
    "# scrape abstraction for input batch size requirements \n",
    "    # https://github.com/timothyyu/gdax-orderbook-ml/issues/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into gdax-python-api (async) replacement for api library\n",
    "    #https://github.com/timothyyu/gdax-orderbook-ml/issues/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mockup design of predicted vs actual \n",
    "    #https://github.com/timothyyu/gdax-orderbook-ml/issues/18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
