{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from json import loads\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "# Charting-specific imports\n",
    "import matplotlib.finance\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.finance import candlestick_ohlc,candlestick2_ohlc\n",
    "from matplotlib.finance import volume_overlay,volume_overlay2\n",
    "from matplotlib.dates import  DateFormatter, epoch2num\n",
    "    # https://matplotlib.org/api/finance_api.html#module-matplotlib.finance\n",
    "\n",
    "# API-specific imports (local install)\n",
    "import gdax\n",
    "    # Python setup.py install with environment activaated to install/use\n",
    "    # Do not use default gdax pip install package - that version of the package is currently broken\n",
    "\n",
    "# Pymongo import for connection to local client DB\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Preprocessing Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "# ML Imports \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "# autoSR() import requirements\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from pandas_datareader import data, wb\n",
    "\n",
    "###########################################################################\n",
    "### Force Keras/TF to use CPU backend when GPU present by setting:\n",
    "    # {'CPU' : 1, 'GPU' : 0}\n",
    "    \n",
    "#num_cores = 4\n",
    "#config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        #inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        #device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "#session = tf.Session(config=config)\n",
    "#K.set_session(session)\n",
    "###########################################################################\n",
    "\n",
    "# Import to check check for GPU availability for tensorflow backend\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# Boolean to drop existing mongo collection/scrape upon scrape() init\n",
    "dropFlag = False\n",
    "\n",
    "# Boolean to set size_delta to l2update values for first update to snapshot\n",
    "#firstUpdate = False\n",
    "firstUpdate_bids = False\n",
    "firstUpdate_asks = False\n",
    "\n",
    "# Value to track if feature_creation_inital() was run\n",
    "feature_creation_intital_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection establishment\n",
    "\n",
    "# Establish connection to GDAX public endpoint\n",
    "public_client = gdax.PublicClient()\n",
    "\n",
    "# Mongo database and collection specification:\n",
    "mongo_client = MongoClient('mongodb://localhost:27017/')\n",
    "db = mongo_client.btcusd_db\n",
    "btcusd_collection = db.btcusd_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to start scrape process from websocket to mongodb instance\n",
    "def scrape_start():\n",
    "    # Drop existing collection from db if dropFlag == True (on new scrape):\n",
    "    if 'btcusd_db' in mongo_client.database_names() and dropFlag is True:\n",
    "        mongo_client['btcusd_db'].drop_collection('btcusd_collection')\n",
    "        #print(mongo_client.database_names())\n",
    "        #print(db.collection_names())\n",
    "        \n",
    "    # Start instance of websocket client for L2 Orderbook + L2 update data request and scrape\n",
    "    wsClient = gdax.WebsocketClient(url=\"wss://ws-feed.gdax.com\", \n",
    "                                products=[\"BTC-USD\"],\\\n",
    "                                message_type=\"subscribe\",\\\n",
    "                                channels =[\"level2\"],\\\n",
    "                                mongo_collection=btcusd_collection,\\\n",
    "                                should_print=False)\n",
    "    \n",
    "    # Save request open time and start websocket\n",
    "    time.sleep(4)\n",
    "    request_time_start=public_client.get_time()\n",
    "    wsClient.start()\n",
    "    \n",
    "    # scrape_time is variable for time between websocket connection start and end\n",
    "        # Defined in seconds\n",
    "        # i.e. 600 seconds = scrape running for 10 minutes\n",
    "    scrape_time = 3600\n",
    "\n",
    "    time.sleep(scrape_time)\n",
    "    # Save request close time and close websocket\n",
    "    request_time_end=public_client.get_time()\n",
    "    wsClient.close()\n",
    "    \n",
    "    # Append request times for open/close of websocket stream to dataframe, save to csv\n",
    "    request_log_df = pd.DataFrame.from_dict({'request start':request_time_start,'request end':request_time_end},orient ='index')\n",
    "    request_log_df.to_csv(\"raw_data/request_log.csv\",header=True,encoding='utf-8',index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropFlag = True\n",
    "scrape_start()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
