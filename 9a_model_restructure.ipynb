{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML model restructure\n",
    "        \n",
    "# Simplified stacked 3-layer model\n",
    "    # Keras sequential model\n",
    "        # Stateful + Return sequence set to True\n",
    "        # Stateful + Return sequence set to False\n",
    "    # Keras functional API\n",
    "        # Stateful + Return sequence set to True\n",
    "        # Stateful + Return sequence set to False\n",
    "    # Raw tensorflow \n",
    "        # Stateful + Return sequence set to True\n",
    "        # Stateful + Return sequence set to False\n",
    "        \n",
    "# Single LSTM with 10 nodes\n",
    "    # Keras sequential model\n",
    "    # Keras functional API\n",
    "    # Raw tensorflow \n",
    "\n",
    "# Implement Bao, Yue, Rao deep learning framework (WT, stacked SAE, Stacked LSTM Model)\n",
    "    # Wavelet transform, python: https://pywavelets.readthedocs.io/en/latest/\n",
    "    # Keras Functional API\n",
    "    # Raw tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (Bidirectional)       (12, 10, 64)              10752     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (Bidirectional)       (12, 10, 64)              24576     \n",
      "_________________________________________________________________\n",
      "LSTM_3 (Bidirectional)       (12, 64)                  24576     \n",
      "_________________________________________________________________\n",
      "Dense_2_output (Dense)       (12, 2)                   130       \n",
      "=================================================================\n",
      "Total params: 60,034\n",
      "Trainable params: 60,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simplified stacked 3-layer model\n",
    "    # Keras sequential model, Stateful + Return sequence set to True\n",
    "    \n",
    "batch_size = 10\n",
    "    # Batch size must be provided/known if RNN/Stateful = True\n",
    "timesteps = 10 \n",
    "data_dim = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True,\n",
    "                            use_bias= False, bias_initializer = 'ones',\n",
    "                            recurrent_dropout = 0.5, dropout = 0.5,\n",
    "                            go_backwards=False,name='main_input'),\n",
    "                            batch_input_shape=(batch_size , timesteps, data_dim ),name=\"LSTM_1\")) \n",
    "                                #input_shape(batch_size, timesteps,features)\n",
    "                                #input_shape(timesteps,features)  \n",
    "        \n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True,stateful=True,\n",
    "                            use_bias= False, bias_initializer = 'ones',\n",
    "                            recurrent_dropout = 0.2, dropout = 0.2),name=\"LSTM_2\"))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=False,stateful=True, \n",
    "                            use_bias= False, bias_initializer = 'ones',\n",
    "                            recurrent_dropout = 0.2, dropout = 0.2),name=\"LSTM_3\"))\n",
    "\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid',name=\"Dense_2_output\"))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.03, decay=1e-6, momentum=0.975, nesterov=True)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'sgd', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_98: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-7997b6fcd042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mhidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Third LSTM here - fix ndim input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mhidden3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    472\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    475\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_98: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Simplified stacked 3-layer model\n",
    "    # Keras Functional model, Stateful + Return sequence set to True\n",
    "    # Recurrent Neural Network\n",
    "    \n",
    "from keras.layers import Input\n",
    "visible = Input(shape=(10,10))\n",
    "hidden1 = LSTM(32, return_sequences=True)(visible)\n",
    "# Second LSTM Here - fix ndim input \n",
    "hidden2 = LSTM(32)(hidden1)\n",
    "# Third LSTM here - fix ndim input\n",
    "hidden3 = LSTM(32)(hidden2)\n",
    "\n",
    "output = Dense(2, activation='sigmoid')(hidden3)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 10, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 10, 32)            5504      \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 10, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 22,474\n",
      "Trainable params: 22,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "visible = Input(shape=(10,10))\n",
    "# feature extraction\n",
    "extract = LSTM(32, return_sequences=True)(visible)\n",
    "extract2 = LSTM(32, return_sequences=True)(extract)\n",
    "#\n",
    "class11 = LSTM(32)(extract2)\n",
    "output1 = Dense(10, activation='sigmoid')(class11)\n",
    "# output\n",
    "model = Model(inputs=visible, outputs=output1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
