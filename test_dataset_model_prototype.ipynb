{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test data to build/prototype-out a ML model\n",
    "    # Further restructuring data for ML input layers\n",
    "        # Variable isolation and selection refinement\n",
    "    # Reshaping, encoding, normalization\n",
    "    # Input, layer, and output specification\n",
    "    # Force keras/tensorflow to use GPU backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Pymongo import for connection to local client DB\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# ML Imports \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "# Preprocessing Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler,OneHotEncoder\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "# Import to check check for GPU availability for tensorflow backend\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mongodb connection for live feed of data into model\n",
    "    # Implementation after verification of test data -> model prototype input layer working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14492975823642502260\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9222031934\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10495751105079177724\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "==============================================\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU availability for tensorflow backend\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"==============================================\")\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test data for L2 orderbook state (bids + asks)\n",
    "    # Read in test data for subsquent L2 orderbook update states (L2 updates to bid + asks)\n",
    "snapshot_asks_df = pd.read_csv(\"test_data/snapshot_asks.csv\")\n",
    "snapshot_bids_df = pd.read_csv(\"test_data/snapshot_bids.csv\")\n",
    "l2update_df = pd.read_csv(\"test_data/l2update.csv\", dtype ={'changes':object})\n",
    "request_log_df= pd.read_csv(\"test_data/request_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                       iso         epoch\n",
      "0    request end  2018-04-17T01:05:03.469Z  1.523927e+09\n",
      "1  request start  2018-04-17T00:55:03.354Z  1.523927e+09\n",
      "===============================================\n",
      "   side    price       size\n",
      "0  sell  8042.91  10.656147\n",
      "1  sell  8042.92   0.001181\n",
      "2  sell  8042.93   0.001305\n",
      "3  sell  8042.94   0.001181\n",
      "4  sell  8042.95   1.265966\n",
      "  side    price      size\n",
      "0  buy  8042.90  9.118009\n",
      "1  buy  8042.83  0.002487\n",
      "2  buy  8042.50  0.420000\n",
      "3  buy  8042.00  0.001000\n",
      "4  buy  8041.33  0.020000\n",
      "===============================================\n",
      "  side    price   size                      time\n",
      "0  buy  8041.33  0.000  2018-04-17T00:55:04.358Z\n",
      "1  buy  8041.43  0.020  2018-04-17T00:55:04.375Z\n",
      "2  buy  7940.12  0.000  2018-04-17T00:55:04.395Z\n",
      "3  buy  8039.00  0.001  2018-04-17T00:55:04.412Z\n",
      "4  buy  7972.56  0.000  2018-04-17T00:55:04.413Z\n",
      "       side    price      size                      time\n",
      "18088  sell  8078.07  0.000000  2018-04-17T01:05:03.247Z\n",
      "18089   buy  8039.05  0.000000  2018-04-17T01:05:03.330Z\n",
      "18090  sell  8040.52  0.005328  2018-04-17T01:05:03.431Z\n",
      "18091   buy  8039.06  0.000000  2018-04-17T01:05:03.452Z\n",
      "18092   buy  8039.00  0.003750  2018-04-17T01:05:03.486Z\n"
     ]
    }
   ],
   "source": [
    "print(request_log_df.head())\n",
    "print(\"===============================================\")\n",
    "print(snapshot_asks_df.head())\n",
    "#snapshot_asks_df = snapshot_asks_df[\"side\",\"price\",\"size\"]\n",
    "print(snapshot_bids_df.head())\n",
    "print(\"===============================================\")\n",
    "print(l2update_df.head())\n",
    "print(l2update_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bid= buy\n",
    "# Ask = sell\n",
    "\n",
    "#L2 snapshot structure\n",
    "    # [side,price,size]\n",
    "    # 'side' added as part of structure for classification\n",
    "    \n",
    "#l2 updates structure\n",
    "    # [side, price, size, time]\n",
    "\n",
    "# Note on GDAX API about l2update structure:\n",
    "    # size of \"0\" indicates the price level can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side     28242\n",
       "price    28242\n",
       "size     28242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot/categorical encoding test\n",
    "\n",
    "#Join together buy and sell side of orderbook for encoding:\n",
    "snapshot_both_df = pd.concat([snapshot_asks_df,snapshot_bids_df], axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "snapshot_both_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot data cat/one-hot encoded:\n",
    "data_s = snapshot_both_df.values\n",
    "X_s = data_s[:,1:3]\n",
    "y_s = data_s[:,0:1]\n",
    "y_s = np.ravel(y_s)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y_s = label_encoder.fit_transform(y_s)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_y_s = encoded_y_s.reshape(len(encoded_y_s), 1)\n",
    "onehot_y_s = onehot_encoder.fit_transform(encoded_y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int64), array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]), array([[8042.91, 10.65614728],\n",
       "        [8042.92, 0.00118097],\n",
       "        [8042.93, 0.00130538],\n",
       "        ...,\n",
       "        [0.03, 7498.221],\n",
       "        [0.02, 25955.001],\n",
       "        [0.01, 153092.98092796]], dtype=object))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_s,onehot_y_s,X_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 data cat/one-hot encoded:\n",
    "data_l2 = l2update_df.values\n",
    "X_l2 = data_l2[:,1:4]\n",
    "y_l2 = data_l2[:,0:1]\n",
    "y_l2 = np.ravel(y_l2)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y_l2 = label_encoder.fit_transform(y_l2)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_y_l2 = encoded_y_l2.reshape(len(encoded_y_l2), 1)\n",
    "onehot_y_l2 = onehot_encoder.fit_transform(encoded_y_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]], dtype=int64), array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]), array([[8041.33, 0.0, '2018-04-17T00:55:04.358Z'],\n",
       "        [8041.43, 0.02, '2018-04-17T00:55:04.375Z'],\n",
       "        [7940.12, 0.0, '2018-04-17T00:55:04.395Z'],\n",
       "        ...,\n",
       "        [8040.52, 0.00532786, '2018-04-17T01:05:03.431Z'],\n",
       "        [8039.06, 0.0, '2018-04-17T01:05:03.452Z'],\n",
       "        [8039.0, 0.00375, '2018-04-17T01:05:03.486Z']], dtype=object))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_l2,onehot_y_l2,X_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
